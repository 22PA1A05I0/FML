{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOb+XfiDWrXVjQZ3QdsNrJ6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/22PA1A05I0/FML/blob/main/Tokenization%2Cstemming_and_Lemmatization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNDupuAX_w5q",
        "outputId": "aaffd7a7-df75-4161-ab5b-0b40f6f9d84c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['That', 'barista', 'keeps', 'looking', 'at', 'me.', 'She’ll', 'probably', 'ask', 'me', 'to', 'leave', 'if', 'I', 'don’t', 'buy', 'something.', 'How', 'was', 'your', 'weekend?', 'she', 'asked']\n",
            "No.of tokens : 23\n"
          ]
        }
      ],
      "source": [
        "text ='''That barista keeps looking at me. She’ll probably ask me to leave if I don’t buy something. How was your weekend? she asked '''\n",
        "tokens = text.split()\n",
        "print(tokens)\n",
        "print(\"No.of tokens :\",len(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text ='''That barista keeps looking at me. She’ll probably ask me to leave if I don’t buy something. How was your weekend? she asked '''\n",
        "sentences = text.split('.')\n",
        "print(sentences)\n",
        "print(\"NO of sentences :\",len(sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dhe9jIuLCR3_",
        "outputId": "ae9e1f86-654f-4f54-dbd0-a352a27d113a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['That barista keeps looking at me', ' She’ll probably ask me to leave if I don’t buy something', ' How was your weekend? she asked ']\n",
            "NO of sentences : 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "BtpvpfjRDnYy"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = re.findall(\"[\\w']+\", text)\n",
        "print(tokens)\n",
        "print(\"No.of tokens : \", len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_utWMEjDh3l",
        "outputId": "a0a47c3d-063e-4fa3-c3a0-4a32d9bcb7bf"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['That', 'barista', 'keeps', 'looking', 'at', 'me', 'She', 'll', 'probably', 'ask', 'me', 'to', 'leave', 'if', 'I', 'don', 't', 'buy', 'something', 'How', 'was', 'your', 'weekend', 'she', 'asked']\n",
            "No.of tokens :  25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = re.compile('[.?!] ').split(text)\n",
        "print(sentences)\n",
        "print(\"No.of sentences : \", len(sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2OITS1WDtOp",
        "outputId": "79f3afd1-e472-48e1-94a2-2882ee5f0d52"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['That barista keeps looking at me', 'She’ll probably ask me to leave if I don’t buy something', 'How was your weekend', 'she asked ']\n",
            "No.of sentences :  4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization using NLTP"
      ],
      "metadata": {
        "id": "ZnBIt-06D2to"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --user -U nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui3dX0IpD8on",
        "outputId": "3a5ff99e-cdcb-488f-f4ae-df262ab14bde"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXXhRmrsEHTf",
        "outputId": "1f819123-b8ad-46f4-b691-d7dddc9d7e16"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)\n",
        "print(\"No.of tokens : \", len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paKvyk_uFrU2",
        "outputId": "df8c26b8-9dac-460a-9411-edb95f00a7d4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['That', 'barista', 'keeps', 'looking', 'at', 'me', '.', 'She', '’', 'll', 'probably', 'ask', 'me', 'to', 'leave', 'if', 'I', 'don', '’', 't', 'buy', 'something', '.', 'How', 'was', 'your', 'weekend', '?', 'she', 'asked']\n",
            "No.of tokens :  30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sentences = sent_tokenize(text)\n",
        "print(sentences)\n",
        "print(\"No.of sentences :\",len(sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKfVGMuQGNf1",
        "outputId": "6aba883a-5554-4550-fb1d-d65549a9c4b1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['That barista keeps looking at me.', 'She’ll probably ask me to leave if I don’t buy something.', 'How was your weekend?', 'she asked']\n",
            "No.of sentences : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "n60hQTDQG5Ep"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "porter = PorterStemmer()\n",
        "print(porter.stem(\"barista\"))\n",
        "print(porter.stem(\"looking\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84GKWbRrHKk2",
        "outputId": "8c8e8aa5-62ff-4270-c5e3-554cb01fb1ee"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "barista\n",
            "look\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "\n",
        "sentence=\"It was a Thursday, but it felt like a Monday to John. And John loved Mondays. He thrived at work. \"\n",
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "def stemSentence(sentence):\n",
        "    token_words=word_tokenize(sentence)\n",
        "    print(token_words)\n",
        "    stem_sentence=[]\n",
        "    for word in token_words:\n",
        "        stem_sentence.append(porter.stem(word))\n",
        "        stem_sentence.append(\" \")\n",
        "    return \"\".join(stem_sentence)\n",
        "\n",
        "x=stemSentence(sentence)\n",
        "print(\"Sentence after stemming :\", x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td4fmBWhIOtp",
        "outputId": "462bed3f-7f48-40df-ef69-78820ac741d2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It', 'was', 'a', 'Thursday', ',', 'but', 'it', 'felt', 'like', 'a', 'Monday', 'to', 'John', '.', 'And', 'John', 'loved', 'Mondays', '.', 'He', 'thrived', 'at', 'work', '.']\n",
            "Sentence after stemming : it wa a thursday , but it felt like a monday to john . and john love monday . he thrive at work . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awWC5DuPKTAE",
        "outputId": "51169078-6366-443a-b1a4-d482fc701e49"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "sentence = \"I fed Loretta, put her to sleep, and played with her. And then her response was…?\"\n",
        "punctuations=\"?:!.,;\"\n",
        "token_words = nltk.word_tokenize(sentence)\n",
        "print(token_words)\n",
        "\n",
        "lemma_sentence=[]\n",
        "for word in token_words:\n",
        "  lemma_sentence.append(wordnet_lemmatizer.lemmatize(word))\n",
        "  lemma_sentence.append(\" \")\n",
        "\n",
        "print(\"lemmas of tokens: \", ''.join(lemma_sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSq7CSdlJQ_P",
        "outputId": "e0ccbf87-e463-405c-9622-94f99604ce72"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'fed', 'Loretta', ',', 'put', 'her', 'to', 'sleep', ',', 'and', 'played', 'with', 'her', '.', 'And', 'then', 'her', 'response', 'was…', '?']\n",
            "lemmas of tokens:  I fed Loretta , put her to sleep , and played with her . And then her response was… ? \n"
          ]
        }
      ]
    }
  ]
}